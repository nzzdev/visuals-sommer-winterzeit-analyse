{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Masternuts and Hexbins\n",
    "Dieses Script erstellt unsere Hexkarte, die Grundlage für alles. Ausserdem werden OSM-Labels geladen, um jede Zelle beschriften zu können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import h3\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.ops import unary_union\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from timezonefinder import TimezoneFinder\n",
    "import consts\n",
    "import overpy\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf:TimezoneFinder = TimezoneFinder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Masternuts - not needed anymore -> Use Hex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Nuts EU\n",
    "gpd_nuts_eu = gpd.read_file(consts.PATH_NUTS_EU)\n",
    "gpd_nuts_eu = gpd_nuts_eu[gpd_nuts_eu.LEVL_CODE == 3]\n",
    "\n",
    "# Remove some countries\n",
    "gpd_nuts_eu = gpd_nuts_eu[~gpd_nuts_eu.CNTR_CODE.isin(['TR'])]\n",
    "\n",
    "# Import Nuts UK\n",
    "gpd_nuts_uk = gpd.read_file(consts.PATH_NUTS_UK)\n",
    "gpd_nuts_uk.rename(columns={\n",
    "    'nuts318cd': 'NUTS_ID',\n",
    "    'nuts318nm': 'NAME_LATN'\n",
    "    }, inplace=True)\n",
    "gpd_nuts_uk.to_crs(gpd_nuts_eu.crs, inplace=True)\n",
    "\n",
    "# Import Bosnia. Has no NUTS\n",
    "gdf_bosnia = gpd.read_file(consts.PATH_BORDERS)\n",
    "gdf_bosnia = gdf_bosnia[gdf_bosnia.CNTR_ID == 'BA']\n",
    "gdf_bosnia.rename(columns={'ISO3_CODE': 'NUTS_ID', 'NAME_ENGL': 'NAME_LATN'}, inplace=True)\n",
    "gdf_bosnia = gdf_bosnia[['NUTS_ID', 'NAME_LATN', 'geometry']]\n",
    "\n",
    "# Merge\n",
    "gpd_nuts = pd.concat([gpd_nuts_eu, gpd_nuts_uk, gdf_bosnia], ignore_index=True)\n",
    "gpd_nuts = gpd_nuts[['NUTS_ID', 'NAME_LATN', 'geometry']]\n",
    "\n",
    "# Add timezone information to the GeoDataFrame\n",
    "gpd_nuts['timezone'] = gpd_nuts.apply(\n",
    "    lambda row: tf.timezone_at(lat=row.geometry.centroid.y, lng=row.geometry.centroid.x), axis=1\n",
    ")\n",
    "\n",
    "# Drop overseas\n",
    "gdf_boundaries = gpd.read_file(consts.PATH_BOUNDARIES)\n",
    "gpd_nuts = gpd.overlay(gpd_nuts, gdf_boundaries, how='intersection')\n",
    "\n",
    "# Save masternuts\n",
    "gpd_nuts.to_file(consts.PATH_MASTERNUTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Hexgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the bounding box for Europe (approximate)\n",
    "min_lat, min_lon = -25.0,34.0\n",
    "max_lat, max_lon = 45.0,72.0\n",
    "\n",
    "# Define the resolution for the hexagons (adjust as needed)\n",
    "resolution = 4  # This resolution corresponds to hexagons with an edge length of ~50 km\n",
    "\n",
    "# Generate hexagons within the bounding box\n",
    "hexagons = []\n",
    "for lat in range(int(min_lat * 100), int(max_lat * 100), 1):\n",
    "    for lon in range(int(min_lon * 100), int(max_lon * 100), 1):\n",
    "        hex_id = h3.latlng_to_cell(lat / 100.0, lon / 100.0, resolution)\n",
    "        hexagons.append(hex_id)\n",
    "\n",
    "# Convert hexagons to polygons\n",
    "hexagon_polygons = [Polygon(h3.cell_to_boundary(h)) for h in set(hexagons)]\n",
    "\n",
    "# Create a GeoDataFrame\n",
    "gdf_hexagons = gpd.GeoDataFrame({'geometry': hexagon_polygons})\n",
    "\n",
    "# Set the coordinate reference system (CRS) to WGS84 (EPSG:4326)\n",
    "gdf_hexagons.crs = 'EPSG:4326'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cut Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Country data\n",
    "df_eu = gpd.read_file(Path('../data/countries-europe.gpkg'))\n",
    "df_eu = df_eu[~df_eu.ISO_A2_EH.isin(['RU', 'BY', 'UA', 'IS'])]\n",
    "df_eu_dissolved = df_eu.dissolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut aloung outer EU border\n",
    "gdf_hexagons_cut = gpd.overlay(gdf_hexagons, df_eu_dissolved, how='intersection')\n",
    "gdf_hexagons_cut = gdf_hexagons_cut[['geometry']].copy()\n",
    "\n",
    "# Cut hexagons along country borders\n",
    "gdf_hexagons_cut = gpd.overlay(gdf_hexagons_cut, df_eu, how='intersection')\n",
    "\n",
    "# Cleanup\n",
    "gdf_hexagons_cut = gdf_hexagons_cut[['geometry']]\n",
    "\n",
    "# Add Timezone\n",
    "gdf_hexagons_cut['timezone'] = gdf_hexagons_cut.apply(\n",
    "    lambda row: tf.timezone_at(lat=row.geometry.centroid.y, lng=row.geometry.centroid.x), axis=1\n",
    ")\n",
    "\n",
    "gdf_hexagons_cut.reset_index(drop=False, inplace=True)\n",
    "gdf_hexagons_cut.rename(columns={'index':'NUTS_ID'}, inplace=True)\n",
    "gdf_hexagons_cut.to_file(consts.PATH_HEXAGON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Labels from OSM\n",
    "* 19 minutes loading from OSM\n",
    "* x minutes saving as GPKG :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_hexagons_union = gpd.read_file(consts.PATH_HEXAGON)\n",
    "gdf_hexagons_union = unary_union(gdf_hexagons_cut.geometry)\n",
    "gdf_hexagons_union = gpd.GeoDataFrame({'geometry': [gdf_hexagons_union]}, crs=gdf_hexagons_cut.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a grid with NxN cells\n",
    "\n",
    "# Get the bounds of the union of hexagons\n",
    "minx, miny, maxx, maxy = gdf_hexagons_union.total_bounds\n",
    "\n",
    "# Define the number of cells in the grid\n",
    "n_cells_x = 5\n",
    "n_cells_y = 5\n",
    "\n",
    "# Calculate the size of each cell\n",
    "cell_width = (maxx - minx) / n_cells_x\n",
    "cell_height = (maxy - miny) / n_cells_y\n",
    "\n",
    "# Generate the grid cells\n",
    "grid_cells = []\n",
    "for i in range(n_cells_x):\n",
    "    for j in range(n_cells_y):\n",
    "        x1 = minx + i * cell_width\n",
    "        y1 = miny + j * cell_height\n",
    "        x2 = x1 + cell_width\n",
    "        y2 = y1 + cell_height\n",
    "        grid_cells.append(Polygon([(x1, y1), (x2, y1), (x2, y2), (x1, y2), (x1, y1)]))\n",
    "\n",
    "# Create a GeoDataFrame with the grid cells\n",
    "gdf_grid = gpd.GeoDataFrame({'geometry': grid_cells}, crs=gdf_hexagons_union.crs)\n",
    "gdf_grid.reset_index(drop=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = overpy.Overpass()\n",
    "\n",
    "def get_features(place, bounds):\n",
    "\n",
    "    x1 = bounds[1]\n",
    "    y1 = bounds[0]\n",
    "    x2 = bounds[3]\n",
    "    y2 = bounds[2]\n",
    "\n",
    "    # Call Overpass\n",
    "    result = api.query(f\"\"\"\n",
    "        (\n",
    "        node[\"place\"=\"{place}\"]({x1},{y1},{x2},{y2});\n",
    "        );\n",
    "        (._;>;);\n",
    "        out body;\n",
    "    \"\"\")\n",
    "\n",
    "    # Create GeoJSON Features\n",
    "    features = []\n",
    "    for n in result.nodes:\n",
    "        features.append({\n",
    "        \"type\": \"Feature\",\n",
    "        \"properties\": n.tags,\n",
    "        \"geometry\": {\n",
    "            \"type\": \"Point\",\n",
    "            \"coordinates\": [\n",
    "                float(n.lon),\n",
    "                float(n.lat)\n",
    "            ]\n",
    "        }\n",
    "    })\n",
    "\n",
    "    return features\n",
    "\n",
    "geojson = {\n",
    "  \"type\": \"FeatureCollection\",\n",
    "  \"features\": []\n",
    "}\n",
    "\n",
    "# Loop every grid cell and get osm data\n",
    "for i, row in gdf_grid.iterrows():\n",
    "    # if row['index'] != 11:\n",
    "    #     continue\n",
    "    print(\"Cell\", row['index'])\n",
    "\n",
    "    bounds = row.geometry.bounds    \n",
    "    geojson['features'] += get_features('city', bounds)\n",
    "    geojson['features'] += get_features('town', bounds)\n",
    "    geojson['features'] += get_features('village', bounds)\n",
    "    # geojson['features'] += get_features('hamlets', bounds)\n",
    "\n",
    "# Temp Export (its faster than reading it from memory)\n",
    "json.dump(geojson, open(Path('../export/citylabels.tmp.geojson'), 'w'), ensure_ascii=False, indent = 2)\n",
    "\n",
    "# Read as GeoDataFrame\n",
    "gdf_labels_raw = gpd.read_file('../export/citylabels.tmp.geojson')\n",
    "gdf_labels = gdf_labels_raw[['geometry','name:de', 'name', 'place', 'rank', 'population']]\n",
    "gdf_labels.to_file('../export/citylabels.gpkg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge OSM-Labels mit Grid, add Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_labels_raw = gpd.read_file('../export/citylabels.gpkg')\n",
    "gdf_hexagons_cut = gpd.read_file(consts.PATH_HEXAGON)\n",
    "\n",
    "# Add place sorting\n",
    "place_sort = {\n",
    "    'city': 100,\n",
    "    'town': 90,\n",
    "    'village': 80\n",
    "}\n",
    "gdf_labels_raw['place_sort'] = gdf_labels_raw['place'].apply(lambda x: place_sort[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6838/6838 [01:42<00:00, 66.95it/s]\n"
     ]
    }
   ],
   "source": [
    "with tqdm(total=len(gdf_hexagons_cut)) as pbar:\n",
    "    for i, row in gdf_hexagons_cut.iterrows():\n",
    "        pbar.update()\n",
    "\n",
    "        points_in_hexagon = gdf_labels_raw[gdf_labels_raw.within(row.geometry)]\n",
    "\n",
    "        if len(points_in_hexagon) > 0:\n",
    "\n",
    "            # Add name\n",
    "            points_in_hexagon = points_in_hexagon.sort_values(['place_sort', 'population'], ascending=[False, True])\n",
    "            name = points_in_hexagon.iloc[0]['name:de'] if points_in_hexagon.iloc[0]['name:de'] else points_in_hexagon.iloc[0]['name']\n",
    "            gdf_hexagons_cut.loc[i, 'name'] = name\n",
    "\n",
    "        else:\n",
    "\n",
    "            # Add Coords as name\n",
    "            coords = row.geometry.centroid.coords[0]\n",
    "            name = f\"N{coords[1]:.3f}, E{coords[0]:.3f}\"\n",
    "            gdf_hexagons_cut.loc[i, 'name'] = name\n",
    "\n",
    "        # Add country name\n",
    "        point = row.geometry.centroid\n",
    "        country = df_eu[df_eu.contains(point)]['NAME_DE'].values\n",
    "        gdf_hexagons_cut.loc[i, 'country'] = country[0] if len(country) > 0 else 'Unknown'\n",
    "\n",
    "# Store\n",
    "gdf_hexagons_cut.to_file(consts.PATH_HEXAGON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
